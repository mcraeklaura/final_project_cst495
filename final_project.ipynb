{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "For our final project we are going to be using the CIFAR10 dataset. This dataset has 60000 color images that are divided into ten different classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. These images are 32x32 pixels and 50000 of them are dedicated as training images and 10,000 of them are for testing. Each of the classes has 5,000 images. The labels are numerical numbers 0-9 that represent the different classes.\n",
    "\n",
    "# Plan\n",
    "Our plan is to create a Convolutional Neural Network that can get the highest accuracy on the test set. Some of our concerns are if there are too many images for the computing power we have currently. There are many paid options we can utilize, but computing time is a concern with us.\n",
    "\n",
    "First, we are planning to try and putting our data into the regular mnist CNN we have been using in class. From there, we will make the necessary changes. Some of the things we want to look into is data augmentation and how creating new data objects from the images we already have would help training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Project 2\n",
    "We were able to get an initial model running, but the accuracy was very low, around 20-30%. However, this is not too bad because if we were to make predictions at random, we would get 10% accuracy. We were using the generic CNN model we were using for the MNIST data, which could be why it is not doing as well, because the MNIST data did not take color and filters into account. We used some of the starter code from the in class lab to try and create a model that would make more accurate predictions.\n",
    "When we were trying out the general data, there was a point in which the training accuracy dropped from 1.0 to .10. We were using batch sizes of 64 and increased it to around 1000 and accuracy went up a lot. We also decided that we should use a drop out layer. One of the reasons we thing that that huge decrease in accuracy happened was because for some reason, it was starting to train on the wrong types of sets, and then when there was a batch with different types of data, all the sudden it performed very poorly. So using dropout, we think we can help improve this issue. We started by using it at .4 to see if it had any affect but it did not. We moved it around to some different places and there was not much difference to the data.\n",
    "\n",
    "## The rest of the plan\n",
    "For the rest of our project we plan to try and dive deep into different issues with this data set and figure out what exactly the model needs to be successful. Moving different layers and pooling around did not seem to help, so we are thinking of adding more layers and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
